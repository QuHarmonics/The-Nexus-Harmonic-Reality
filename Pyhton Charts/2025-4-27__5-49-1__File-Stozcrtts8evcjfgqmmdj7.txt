Conversation URL:
https://chatgpt.com/c/680df9f3-914c-8011-9dc7-ff1733e4cfe2

Title:


Prompt:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import display

# 1. Generate a test random-walk stream
def generate_random_walk(N=1000, seed=0):
    np.random.seed(seed)
    return np.cumsum(np.random.randn(N))

# 2. Novelty checkpoint + motif compression with length sweep and harmonic bias
def novelty_motif_compression(stream, base_eps, adaptive, min_len, max_len, bias, k=0.35, window_vol=10):
    deltas = np.diff(stream)
    N = len(deltas)
    # Precompute volatility for adaptive epsilon
    vol = np.array([np.std(deltas[max(0, i-window_vol):i+1]) for i in range(N)])
    
    # Journal deltas by epsilon
    journal = []
    for i, d in enumerate(deltas):
        eps = (base_eps * vol[i]) if adaptive else base_eps
        if abs(d) > eps:
            journal.append(d)
    # Setup compression
    motif_dict = {}  # seq -> id
    next_id = 0
    tokens = []
    storage_tokens = 0
    checkpoints = 0
    pos = 0
    journal = list(journal)
    # Compression loop
    while pos < len(journal):
        # Try existing motifs first (longest match)
        matched = False
        for L in range(max_len, min_len-1, -1):
            if pos + L <= len(journal):
                seq = tuple(journal[pos:pos+L])
                if seq in motif_dict:
                    tokens.append(('M', motif_dict[seq]))
                    storage_tokens += 1
                    pos += L
                    matched = True
                    break
        if matched:
            continue
        # No existing motif: emit literal, maybe add new motif + checkpoint
        tokens.append(('D', journal[pos]))
        storage_tokens += 1
        # Build candidate new motifs of lengths [min_len..max_len]
        candidates = []
        for L in range(min_len, max_len+1):
            if pos + L <= len(journal):
                seq = tuple(journal[pos:pos+L])
                candidates.append(seq)
        # Choose which to add
        if candidates:
            if bias:
                # select seq whose average delta is closest to k
                best = min(candidates, key=lambda s: abs(np.mean(s) - k))
                motif_dict[best] = next_id
                next_id += 1
                checkpoints += 1
            else:
                # add all new to dict, checkpoint on first only
                first_added = False
                for seq in candidates:
                    if seq not in motif_dict:
                        motif_dict[seq] = next_id
                        next_id += 1
                        if not first_added:
                            checkpoints += 1
                            first_added = True
        pos += 1
    
    total_storage = storage_tokens + checkpoints
    # Reconstruction
    reconstructed = np.zeros(len(stream))
    idx = 1  # start from second element for deltas
    inv_motifs = {v: k for k, v in motif_dict.items()}
    for typ, val in tokens:
        if typ == 'M':
            seq = inv_motifs[val]
            for d in seq:
                reconstructed[idx] = reconstructed[idx-1] + d
                idx += 1
        else:
            d = val
            reconstructed[idx] = reconstructed[idx-1] + d
            idx += 1
    # Compute RMSE
    rmse = np.sqrt(np.mean((reconstructed - stream)**2))
    return total_storage / N, rmse

# 3. Sweep parameters
stream = generate_random_walk(1000)
epsilon_bases = [0.5, 1.0, 2.0, 4.0]
schemes = [False, True]  # fixed, adaptive
motif_lengths = list(range(2, 9))
bias_options = [False, True]

results = []
for adaptive in schemes:
    for eps in epsilon_bases:
        for min_len in motif_lengths:
            for bias in bias_options:
                max_len = min_len + 3  # window size of 4 lengths
                storage_ratio, rmse = novelty_motif_compression(
                    stream, eps, adaptive, min_len, max_len, bias
                )
                results.append({
                    'scheme': 'adaptive' if adaptive else 'fixed',
                    'base_eps': eps,
                    'min_motif_len': min_len,
                    'max_motif_len': max_len,
                    'bias': bias,
                    'storage_ratio': storage_ratio,
                    'rmse': rmse
                })

df = pd.DataFrame(results)

# 4. Display the result table
display(df.head(20))

# 5. Plot RMSE vs Storage Ratio for bias on/off, picking a single eps for clarity
for bias in [False, True]:
    plt.figure(figsize=(6,4))
    subset = df[(df['base_eps']==1.0) & (df['bias']==bias)]
    for scheme, marker in [('fixed','o'), ('adaptive','x')]:
        df_s = subset[subset['scheme']==scheme]
        plt.scatter(df_s['storage_ratio'], df_s['rmse'], label=scheme, marker=marker)
    plt.title(f'Novelty + Motif (Îµ=1.0), bias={bias}')
    plt.xlabel('Total Storage Ratio')
    plt.ylabel('RMSE')
    plt.legend()
    plt.grid(True)
    plt.show()