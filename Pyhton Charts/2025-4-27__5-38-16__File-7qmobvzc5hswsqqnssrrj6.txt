Conversation URL:
https://chatgpt.com/c/680df8d1-c038-8011-b644-837635a78eee

Title:


Prompt:
import numpy as np
import matplotlib.pyplot as plt

# Parameters
k = 0.35  # harmonic constant
steps = 50  # number of iterations per simulation
grid_size = 100  # resolution for beta and gamma grid
tol_plot = 0.15  # new, tighter tolerance for contour

# Create grid of beta and gamma values
betas = np.linspace(0, 2, grid_size)
gammas = np.linspace(0, 2, grid_size)
error_map = np.zeros((grid_size, grid_size))

# Simulation of measurement+drift
for i, beta in enumerate(betas):
    for j, gamma in enumerate(gammas):
        H = 0.5  # initial anchor
        S = 1.0  # initial state
        for _ in range(steps):
            # Measurement step
            delta = S - H
            S -= beta * delta
            H += gamma * delta
            # Drift step
            delta = S - H
            S -= k * delta
        error_map[j, i] = abs(S - k)

# Plot updated heatmap with contour at the new tolerance
plt.figure(figsize=(6, 5))
plt.title(f"Convergence Error with contour at error = {tol_plot}")
plt.xlabel("β")
plt.ylabel("γ")
im = plt.imshow(error_map, origin='lower', extent=(0, 2, 0, 2), aspect='auto')
contour = plt.contour(betas, gammas, error_map, levels=[tol_plot], colors='white', linewidths=1.5)
plt.clabel(contour, fmt={tol_plot: f"error = {tol_plot}"}, inline=True)
plt.colorbar(im, label="|S_final - k|")
plt.tight_layout()
plt.show()